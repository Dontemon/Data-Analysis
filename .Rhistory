plot(age, y)
while (dev.cur() != 1) {
dev.off()
}
rm(list=ls())
cat("\014")
n = 50
a = 0
b = 80
age = sample(a:b, n,  replace = TRUE)
sigma = 5
eps = rnorm (n, 0, sigma)
theta0 = -8
theta1 = 0.2
P_x = exp(theta0 + theta1 * age + eps) / (1 + exp(theta0 + theta1 * age + eps))
y = ifelse(P_x < 0.5, 0, 1)
plot(age, y)
while (dev.cur() != 1) {
dev.off()
}
rm(list=ls())
cat("\014")
n = 50
a = 0
b = 80
age = sample(a:b, n,  replace = TRUE)
sigma = 5
eps = rnorm (n, 0, sigma)
theta0 = -8
theta1 = 0.2
P_x = exp(theta0 + theta1 * age + eps) / (1 + exp(theta0 + theta1 * age + eps))
y = ifelse(P_x < 0.5, 0, 1)
plot(age, y)
while (dev.cur() != 1) {
dev.off()
}
rm(list=ls())
cat("\014")
n = 50
a = 0
b = 80
age = sample(a:b, n,  replace = TRUE)
sigma = 5
eps = rnorm (n, 0, sigma)
theta0 = -8
theta1 = 0.2
P_x = exp(theta0 + theta1 * age + eps) / (1 + exp(theta0 + theta1 * age + eps))
y = ifelse(P_x < 0.5, 0, 1)
plot(age, y)
Y = ifelse(P_x < 0.5, 0, 1)
plot(age, Y)
logreg = glm(Y~age, family = binomial(link = "logit"))
logreg
summary(logreg)
predict(logreg, new_data,  type = "response")
new_data = data.frame(age = 23)
predict(logreg, new_data,  type = "response")
new_data = data.frame(age = 80)
predict(logreg, new_data,  type = "response")
new_data = data.frame(age = 80)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
new_data = data.frame(age = 40)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
round(predict(logreg, new_data,  type = "response"), digits = 0)
round(predict(logreg, new_data,  type = "response"), digits = 0)
new_data = data.frame(age = 100)
round(predict(logreg, new_data,  type = "response"), digits = 0)
new_data = data.frame(age = 10000)
round(predict(logreg, new_data,  type = "response"), digits = 0)
new_data = data.frame(age = 40)
round(predict(logreg, new_data,  type = "response"), digits = 0)
new_data = data.frame(age = 45)
round(predict(logreg, new_data,  type = "response"), digits = 0)
new_data = data.frame(age = 43)
round(predict(logreg, new_data,  type = "response"), digits = 0)
new_data = data.frame(age = 41)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 41)
value[2] = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 41)
value[2,] = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 41)
value[] = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 42)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 43)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 44)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 45)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 44.5)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 44.4)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 44.3)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
new_data = data.frame(age = 44.2)
value = predict(logreg, new_data,  type = "response")
round(value, digits = 0)
value
new_data = data.frame(age = 44.25)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.24)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.22)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.23)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.22)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.225)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.226)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.227)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.229)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.2291)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.2292)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.2291)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.22911)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.22915)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.22918)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 44.22919)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
new_data = data.frame(age = 44)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
new_data = data.frame(age = 30)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
library(pROC)
install.packages("pROC")
library(pROC)
roc_obj = roc(y, fitted(logreg))
auc_value = auc(roc_obj)
roc_obj
print(paste("AUC:", auc_value))
plot(roc_obj, main = "ROC Curve")
# Задание 1. Формирование выборки ----
while (dev.cur() != 1) {
dev.off()
}
rm(list=ls())
cat("\014")
n = 50
a = 0
b = 80
age = sample(a:b, n,  replace = TRUE)
sigma = 5
eps = rnorm (n, 0, sigma)
theta0 = -8
theta1 = 0.2
P_x = exp(theta0 + theta1 * age + eps) / (1 + exp(theta0 + theta1 * age + eps))
Y = ifelse(P_x < 0.5, 0, 1)
plot(age, Y)
logreg = glm(Y~age, family = binomial(link = "logit"))
summary(logreg)
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 50)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 45)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 42)
value = predict(logreg, new_data,  type = "response")
value
new_data = data.frame(age = 41)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
new_data = data.frame(age = 42)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
new_data = data.frame(age = 43)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
new_data = data.frame(age = 44)
value = predict(logreg, new_data,  type = "response")
value
round(value, digits = 0)
#install.packages("pROC")
library(pROC)
roc_obj = roc(Y, fitted(logreg))
auc_value = auc(roc_obj) # Чем ближе AUC к 1, тем лучше модель.
plot(roc_obj, main = "ROC Curve")
# Библиотека ----
library(shiny)
library(shiny)
# Библиотека ----
install.packages("shiny")
library(shiny)
runExample("01_hello")
while (dev.cur() != 1) {
dev.off()
}
rm(list=ls())
cat("\014")
library(shiny)
library(corrplot)
library(ggplot2)
library(randomForest)
library(xgboost)
library(readr)
library(dplyr)
library(psych)
library(writexl)
# Очистка рабочего пространства ----
while (dev.cur() != 1) {
dev.off()
}
rm(list=ls())
cat("\014")
# Загрузка данных ----
#price - price in US dollars (\$326--\$18,823)
#carat (0,2-5,01) - weight of the diamond (0.2--5.01)
#cut - quality of the cut (Fair, Good, Very Good, Premium, Ideal)
#color - diamond color, from J (worst) to D (best)
#clarity - a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))
#depth - total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)
#table - width of top of diamond relative to widest point (43--95)
#x - length in mm (0--10.74)
#y - width in mm (0--58.9)
#z - depth in mm (0--31.8)
setwd("D:/Data-Analysis/") #установка рабочей директории
diamonds = read.csv("diamonds.csv") #чтение данных из файла
#write_xlsx(diamonds, "diamonds.xlsx")
#Заполнение нулевых значений средними значениями
diamonds = diamonds %>%
mutate(x = ifelse(x == 0, mean(x[x != 0], na.rm = TRUE), x),
y = ifelse(y == 0, mean(y[y != 0], na.rm = TRUE), y),
z = ifelse(z == 0, mean(z[z != 0], na.rm = TRUE), z))
#удаление первого столбца (индексация)
diamonds = diamonds %>%
select(-1)
#удаление дубликатов
diamonds = diamonds %>%
filter(!duplicated(.))
replace_outliers_with_mean_exclude = function(column) {
Q1 = quantile(column, 0.25)
Q3 = quantile(column, 0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
# Определение выбросов
outliers = column < lower_bound | column > upper_bound
# Замена выбросов на среднее значение, исключая выбросы
column[outliers] = mean(column, na.rm = TRUE)
return(column)
}
#В данных очень много выбросов
boxplot(diamonds$carat)
diamonds$carat=replace_outliers_with_mean_exclude(diamonds$carat); boxplot(diamonds$carat)
diamonds$carat=replace_outliers_with_mean_exclude(diamonds$carat); boxplot(diamonds$carat)
boxplot(diamonds$depth)
diamonds$depth=replace_outliers_with_mean_exclude(diamonds$depth); boxplot(diamonds$depth)
diamonds$depth=replace_outliers_with_mean_exclude(diamonds$depth); boxplot(diamonds$depth)
diamonds$depth=replace_outliers_with_mean_exclude(diamonds$depth); boxplot(diamonds$depth)
diamonds$depth=replace_outliers_with_mean_exclude(diamonds$depth); boxplot(diamonds$depth)
boxplot(diamonds$table)
diamonds$table=replace_outliers_with_mean_exclude(diamonds$table); boxplot(diamonds$table)
boxplot(diamonds$x)
diamonds$x=replace_outliers_with_mean_exclude(diamonds$x); boxplot(diamonds$x)
boxplot(diamonds$y)
diamonds$y=replace_outliers_with_mean_exclude(diamonds$y); boxplot(diamonds$y)
boxplot(diamonds$z)
diamonds$z=replace_outliers_with_mean_exclude(diamonds$z); boxplot(diamonds$z)
#Вывод информации о типе и структуре данных
str(diamonds); summary(diamonds)
#Сохранение средних и среднекв.отклонений (для нормализации введенных данных в приложении)
means = colMeans(diamonds[, c("carat", "depth", "table", "x", "y", "z")])
sds = apply(diamonds[, c("carat", "depth", "table", "x", "y", "z")], 2, sd)
means_table = data.frame(
carat = means["carat"],
depth = means["depth"],
table = means["table"],
x = means["x"],
y = means["y"],
z = means["z"]
)
write_xlsx(means_table, "means.xlsx")
sds_table = data.frame(
carat = sds["carat"],
depth = sds["depth"],
table = sds["table"],
x = sds["x"],
y = sds["y"],
z = sds["z"]
)
write_xlsx(sds_table, "sds.xlsx")
#Нормализация данных
diamonds$carat = scale(diamonds$carat)
diamonds$depth = scale(diamonds$depth)
diamonds$table = scale(diamonds$table)
diamonds$x = scale(diamonds$x)
diamonds$y = scale(diamonds$y)
diamonds$z = scale(diamonds$z)
#Корреляционный анализ ----
data = diamonds
#преобразование категориальных факторов для проверки корреляции
cut_levels = c("Fair" = 1, "Good" = 2, "Very Good" = 3, "Ideal" = 4, "Premium" = 5)
data$cut = cut_levels[data$cut]
color_levels = c("D" = 7, "E" = 6, "F" = 5, "G" = 4, "H" = 3, "I" = 2, "J" = 1)
data$color = color_levels[data$color]
clarity_levels = c("I1" = 1, "SI2" = 2, "SI1" = 3, "VS2" = 4, "VS1" = 5, "VVS2" = 6, "VVS1" = 7, "IF" = 8)
data$clarity = clarity_levels[data$clarity]
#корреляционная матрица
data = subset(data, select = c("price", "carat", "cut", "color", "clarity", "depth", "table", "x", "y","z"))
cor(data)
#график корреляций
corrplot(cor(data), method = "color", type = "lower")
# Random Forest ----
diamonds = subset(diamonds, select = c("carat", "cut", "color", "clarity", "depth", "table", "price", "x", "y","z"))
#преобразование факторов
diamonds$cut = as.factor(diamonds$cut)
diamonds$color = as.factor(diamonds$color)
diamonds$clarity = as.factor(diamonds$clarity)
set.seed(123)
# Разделение данных на обучающий и тестовый наборы
sample_size = floor(0.7 * nrow(diamonds))
train_indices = sample(seq_len(nrow(diamonds)), size = sample_size)
train = diamonds[train_indices, ]
test = diamonds[-train_indices, ]
#Исследовательские графики
#График, показывающий распределение цен в зависимости от качества огранки и цвета бриллиантов
ggplot(train)+
geom_boxplot(aes(y=price,x=cut,fill=cut),outlier.size=0.1,notch=T,notchwidth=0.2)+
facet_grid(~color,margins=T)+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
ylab(label='Price')+
xlab('Cut')+
ggtitle('Price distribution vs Cut for each colour')
#График, показывающий распределение цен в зависимости от веса бриллианта и качества огранки
ggplot(train)+
geom_point(aes(y=price,x=carat,color=cut))+
scale_x_log10()+scale_y_log10()+
facet_grid(~cut)+
ylab('Price')+
xlab('Carat')+
ggtitle('Price distribution vs Carat')
#График, показывающий распределение цен в зависимости от веса бриллианта
ggplot(train)+
geom_point(aes(y=price,x=carat,color=cut))+
ylab('Price')+
xlab('Carat')+
ggtitle('Price vs Carat')
#График плотности распределения цен в зависимости от качества огранки
ggplot(train)+
geom_density(aes(x=price,fill=cut),alpha=0.2)+
xlab('Price')+
ylab('Density')+
ggtitle('Price distribution')
#График, показывающий распределение цен в зависимости от глубины огранки и качества огранки
ggplot(train)+
geom_point(aes(y=price,x=depth,color=cut))+
xlab('Depth')+
ylab('Price')
# Определение зависимой переменной
response_variable <- "price"
# Обучение модели Random Forest
rf_model = randomForest(formula = as.formula(paste(response_variable, "~ .")), data = train, ntree = 100)
imp=importance(rf_model) # вычисление важности каждого признака в модели
vars=dimnames(imp)[[1]] # извлечение имени признаков
imp=data.frame(vars=vars,imp=as.numeric(imp[,1])) # создание DataFrame с именем признака и его важностью в модели
imp=imp[order(imp$imp,decreasing=T),] #сортировка по убыванию важности признаков
par(mfrow=c(1,2)) #для построения двух графиков
varImpPlot(rf_model,main='Variable Importance Plot: Base Model')
plot(rf_model,main='Error vs No. of trees plot: Base Model')
# Предсказание на тестовом наборе
predictions = predict(rf_model, newdata = test)
rmse1 = sqrt(mean((test$price - predictions)^2))
cat("RMSE: ", rmse1, "\n")
set.seed(123)
selected=c(as.character(imp[1:6,1]),'price') #берём первые 6 факторов
rf_model = randomForest(formula = as.formula(paste(response_variable, "~ .")), data = train[, selected], ntree = 100, mtry = 3, maxdepth = 10, nodesize = 5)
par(mfrow=c(1,2)) #для построения двух графиков
varImpPlot(rf_model,main='Variable Importance Plot: Base Model')
plot(rf_model,main='Error vs No. of trees plot: Base Model')
# Предсказание на тестовом наборе
predictions = predict(rf_model, newdata = test)
rmse2 = sqrt(mean((test$price - predictions)^2))
cat("RMSE: ", rmse2, "\n")
actual=test$price
result=data.frame(actual=actual,predicted=predictions)
ggplot(result)+
geom_point(aes(x=actual,y=predicted,color=predicted-actual),alpha=0.7)+
ggtitle('Plotting Error')
#это связано с тем, что количесво цен до 3000$ намного больше, поэтому модель достаточно хорошо предскажет цены для простых брилиантов
new_data = data.frame(carat = 1.26, cut = "Ideal", color = "G",	clarity = "VVS2",	depth=60.7,	table=56,	x=7.05, y=7.03,	z=4.27) #22520 строка Лучший результат 10581.99
# Нормализуем новые данные с использованием средних и стандартных отклонений из таблицы diamonds
new_data$carat = (new_data$carat - means["carat"]) / sds["carat"]
new_data$depth = (new_data$depth - means["depth"]) / sds["depth"]
new_data$table = (new_data$table - means["table"]) / sds["table"]
new_data$x = (new_data$x - means["x"]) / sds["x"]
new_data$y = (new_data$y - means["y"]) / sds["y"]
new_data$z = (new_data$z - means["z"]) / sds["z"]
new_data$color = factor(new_data$color, levels = levels(diamonds$color))
new_data$clarity = factor(new_data$clarity, levels = levels(diamonds$clarity))
new_data$cut = factor(new_data$cut, levels = levels(diamonds$cut))
prediction = predict(rf_model, new_data)
prediction
# Создание матриц DMatrix для обучающей и тестовой выборок
train[] <- lapply(train, as.numeric) #приводим значения столбцов обучающей выборки к числовому типу
test[] <- lapply(test, as.numeric) #приводим значения столбцов тестовой выборки к числовому типу
dtrain <- xgb.DMatrix(as.matrix(train[, -1]), label = train$price) #создаем матрицу для обучающей выборки, убираем первый столбец и указываем целевую переменную
dtest <- xgb.DMatrix(as.matrix(test[, -1]), label = test$price) #создаем матрицу для тестовой выборки, убираем первый столбец и указываем целевую переменную
# Определение параметров модели XGBoost
params <- list( #создаем список параметров модели
objective = "reg:squarederror", #целевая переменная для регрессии
eta = 0.01, #скорость обучения (learning rate)
max_depth = 6, #максимальная глубина дерева
min_child_weight = 1, #минимальное количество обучающих примеров в листе дерева
subsample = 0.8, #доля обучающих примеров, используемых для обучения каждого дерева
colsample_bytree = 0.8 #доля признаков, используемых для обучения каждого дерева
)
watchlist <- list(train = dtrain, valid = dtest) #список данных для отслеживания обучения
# Обучение модели на обучающей выборке
model <- xgb.train( #обучаем модель
params = params, #передаем параметры модели
data = dtrain, #передаем данные для обучения
nrounds = 5000, #максимальное количество итераций
early_stopping_rounds = 10, #количество итераций без улучшения модели, при которых обучение останавливается
watchlist = watchlist, #передаем список данных для отслеживания обучения
verbose = 0 #уровень вывода информации об обучении модели
)
predictions = predict(model, newdata = test)
predictions = predict(model, newdata = dtest)
rmse3 = sqrt(mean((test$price - predictions)^2))
cat("RMSE: ", rmse3, "\n")
new_data = data.frame(carat = 1.26, cut = "Ideal", color = "G",	clarity = "VVS2",	depth=60.7,	table=56,	x=7.05, y=7.03,	z=4.27) #22520 строка Лучший результат 10581.99
new_data$carat = (new_data$carat - means["carat"]) / sds["carat"]
new_data$depth = (new_data$depth - means["depth"]) / sds["depth"]
new_data$table = (new_data$table - means["table"]) / sds["table"]
new_data$x = (new_data$x - means["x"]) / sds["x"]
new_data$y = (new_data$y - means["y"]) / sds["y"]
new_data$z = (new_data$z - means["z"]) / sds["z"]
new_data$cut <- as.numeric(as.factor(new_data$cut))
new_data$color <- as.numeric(as.factor(new_data$color))
new_data$clarity <- as.numeric(as.factor(new_data$clarity))
colnames(new_data) <- colnames(train)[2:10]
dnew <- xgb.DMatrix(as.matrix(new_data))
new_price <- predict(model, dnew)
new_price
